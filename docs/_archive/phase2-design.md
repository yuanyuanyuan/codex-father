# Phase 2: æµ‹è¯•ä½“ç³»å®Œå–„ - è®¾è®¡æ–‡æ¡£

## 1. è®¾è®¡æ¦‚è¿°

### 1.1 æµ‹è¯•æ¶æ„ç›®æ ‡

æ„å»ºå…¨é¢ã€å¯æ‰©å±•ã€é«˜æ•ˆçš„æµ‹è¯•ä½“ç³»ï¼Œç¡®ä¿ Codex
Father é¡¹ç›®åœ¨åŠŸèƒ½å®Œæ•´æ€§ã€æ€§èƒ½ç¨³å®šæ€§ã€å®‰å…¨å¯é æ€§ç­‰æ–¹é¢è¾¾åˆ°ç”Ÿäº§çº§åˆ«çš„è´¨é‡æ ‡å‡†ã€‚

### 1.2 è®¾è®¡åŸåˆ™

- **åˆ†å±‚æµ‹è¯•**: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€ç«¯åˆ°ç«¯æµ‹è¯•çš„æ¸…æ™°åˆ†å±‚
- **è‡ªåŠ¨åŒ–ä¼˜å…ˆ**: æœ€å¤§åŒ–è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ï¼Œå‡å°‘æ‰‹å·¥æµ‹è¯•ä¾èµ–
- **å¿«é€Ÿåé¦ˆ**: æµ‹è¯•æ‰§è¡Œæ—¶é—´ä¼˜åŒ–ï¼Œæ”¯æŒå¿«é€Ÿå¼€å‘è¿­ä»£
- **ç¯å¢ƒä¸€è‡´æ€§**: ç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒçš„ä¸€è‡´æ€§
- **å¯ç»´æŠ¤æ€§**: æµ‹è¯•ä»£ç çš„å¯è¯»æ€§ã€å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§

### 1.3 æŠ€æœ¯æ ˆé€‰å‹

- **Bash æµ‹è¯•**: BATS (Bash Automated Testing System)
- **TypeScript æµ‹è¯•**: Jest + è‡ªå®šä¹‰ MCP æµ‹è¯•æ¡†æ¶
- **å®‰å…¨æ‰«æ**: ShellCheck + ESLint Security + npm audit
- **CI/CD**: GitHub Actions + Docker å®¹å™¨åŒ–æµ‹è¯•
- **æŠ¥å‘Šç”Ÿæˆ**: JSON + HTML + Markdown å¤šæ ¼å¼æŠ¥å‘Š

## 2. æµ‹è¯•æ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æµ‹è¯•æ¶æ„

```mermaid
graph TB
    subgraph "æµ‹è¯•æ‰§è¡Œå±‚"
        TR[æµ‹è¯•è¿è¡Œå™¨]
        TM[æµ‹è¯•ç®¡ç†å™¨]
        TE[æµ‹è¯•æ‰§è¡Œå¼•æ“]
    end

    subgraph "æµ‹è¯•ç±»å‹å±‚"
        UT[å•å…ƒæµ‹è¯•]
        IT[é›†æˆæµ‹è¯•]
        E2E[ç«¯åˆ°ç«¯æµ‹è¯•]
        ST[å®‰å…¨æµ‹è¯•]
    end

    subgraph "æµ‹è¯•æ”¯æŒå±‚"
        TD[æµ‹è¯•æ•°æ®ç®¡ç†]
        TEnv[æµ‹è¯•ç¯å¢ƒç®¡ç†]
        TM_Mock[Mockå’ŒStub]
        TUtil[æµ‹è¯•å·¥å…·é›†]
    end

    subgraph "æŠ¥å‘Šå’Œåˆ†æå±‚"
        TR_Gen[æŠ¥å‘Šç”Ÿæˆå™¨]
        TMetrics[æŒ‡æ ‡æ”¶é›†å™¨]
        TDash[æµ‹è¯•ä»ªè¡¨æ¿]
        TAnalysis[è¶‹åŠ¿åˆ†æ]
    end

    subgraph "CI/CD é›†æˆå±‚"
        GHA[GitHub Actions]
        DockerTest[Dockeræµ‹è¯•ç¯å¢ƒ]
        QualityGate[è´¨é‡é—¨æ§]
    end

    TR --> UT
    TR --> IT
    TR --> E2E
    TR --> PT
    TR --> ST

    UT --> TD
    IT --> TD
    E2E --> TEnv
    PT --> TMetrics
    ST --> TUtil

    TE --> TR_Gen
    TR_Gen --> TDash
    TMetrics --> TAnalysis

    TR --> GHA
    GHA --> DockerTest
    GHA --> QualityGate
```

### 2.2 æµ‹è¯•æ¡†æ¶åˆ†å±‚è®¾è®¡

#### 2.2.1 æµ‹è¯•è¿è¡Œå™¨æ¶æ„ (tests/lib/test-runner.sh)

```bash
#!/bin/bash
# tests/lib/test-runner.sh - ç»Ÿä¸€æµ‹è¯•è¿è¡Œå™¨

# æµ‹è¯•è¿è¡Œå™¨é…ç½®
readonly TEST_RUNNER_VERSION="1.0.0"
readonly TEST_CONFIG_DIR="tests/config"
readonly TEST_RESULTS_DIR="tests/results"
readonly TEST_ARTIFACTS_DIR="tests/artifacts"

# æµ‹è¯•å¥—ä»¶å®šä¹‰
declare -A TEST_SUITES=(
    ["unit"]="tests/unit/**/*.bats"
    ["integration"]="tests/integration/**/*.bats"
    ["e2e"]="tests/e2e/**/*.bats"
    ["security"]="tests/security/**/*.sh"
)

# ä¸»è¦æµ‹è¯•è¿è¡Œå‡½æ•°
run_test_suite() {
    local suite_name="$1"
    local test_filter="$2"
    local environment="$3"
    local parallel="${4:-false}"

    validate_test_suite "$suite_name" || return 1
    setup_test_environment "$environment" || return 1

    local test_session_id
    test_session_id="test-$(date +%Y%m%d-%H%M%S)-$$"

    log_info "å¯åŠ¨æµ‹è¯•å¥—ä»¶: $suite_name (Session: $test_session_id)"

    # åˆ›å»ºæµ‹è¯•ä¼šè¯ç›®å½•
    local session_dir="${TEST_RESULTS_DIR}/${test_session_id}"
    mkdir -p "$session_dir"

    # åˆå§‹åŒ–æµ‹è¯•æŠ¥å‘Š
    init_test_report "$session_dir" "$suite_name"

    # æ‰§è¡Œæµ‹è¯•
    case "$suite_name" in
        "unit"|"integration"|"e2e")
            run_bats_tests "$suite_name" "$test_filter" "$session_dir" "$parallel"
            ;;
        "security")
            run_security_tests "$test_filter" "$session_dir"
            ;;
        "all")
            run_all_test_suites "$test_filter" "$session_dir" "$parallel"
            ;;
    esac

    local test_result=$?

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    generate_test_report "$session_dir" "$suite_name"

    # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
    cleanup_test_environment "$test_session_id"

    log_info "æµ‹è¯•å¥—ä»¶å®Œæˆ: $suite_name (Result: $test_result)"
    return $test_result
}

# BATS æµ‹è¯•æ‰§è¡Œå™¨
run_bats_tests() {
    local suite_name="$1"
    local test_filter="$2"
    local session_dir="$3"
    local parallel="$4"

    local test_pattern="${TEST_SUITES[$suite_name]}"
    local test_files=()

    # æ”¶é›†æµ‹è¯•æ–‡ä»¶
    while IFS= read -r -d '' file; do
        if [[ -z "$test_filter" ]] || [[ "$file" =~ $test_filter ]]; then
            test_files+=("$file")
        fi
    done < <(find tests -name "*.bats" -path "$test_pattern" -print0)

    if [[ ${#test_files[@]} -eq 0 ]]; then
        log_warn "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æµ‹è¯•æ–‡ä»¶: $test_pattern"
        return 0
    fi

    log_info "å‘ç° ${#test_files[@]} ä¸ªæµ‹è¯•æ–‡ä»¶"

    # é…ç½® BATS æ‰§è¡Œé€‰é¡¹
    local bats_opts=(
        "--formatter" "json"
        "--output" "$session_dir"
        "--timing"
    )

    if [[ "$parallel" == "true" ]]; then
        bats_opts+=("--jobs" "$(nproc)")
    fi

    # æ‰§è¡Œ BATS æµ‹è¯•
    bats "${bats_opts[@]}" "${test_files[@]}"
    local bats_result=$?

    # å¤„ç†æµ‹è¯•ç»“æœ
    process_bats_results "$session_dir" "$suite_name"

    return $bats_result
}
```

#### 2.2.2 æµ‹è¯•ç¯å¢ƒç®¡ç† (tests/lib/test-env.sh)

```bash
#!/bin/bash
# tests/lib/test-env.sh - æµ‹è¯•ç¯å¢ƒç®¡ç†

# ç¯å¢ƒç±»å‹å®šä¹‰
readonly ENV_TYPE_LOCAL="local"
readonly ENV_TYPE_CI="ci"
readonly ENV_TYPE_CONTAINER="container"

# æµ‹è¯•ç¯å¢ƒé…ç½®
declare -A ENV_CONFIG=(
    ["local.isolation"]="process"
    ["local.cleanup"]="standard"
    ["local.temp_dir"]="/tmp/codex-father-test"
    ["ci.isolation"]="container"
    ["ci.cleanup"]="complete"
    ["ci.temp_dir"]="/tmp/cf-ci-test"
    ["container.isolation"]="namespace"
    ["container.cleanup"]="complete"
    ["container.temp_dir"]="/workspace/test-tmp"
)

# ç¯å¢ƒåˆå§‹åŒ–
setup_test_environment() {
    local env_type="$1"
    local test_session_id="$2"

    validate_environment_type "$env_type" || return 1

    log_info "åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ: $env_type"

    # è®¾ç½®ç¯å¢ƒå˜é‡
    setup_environment_variables "$env_type" "$test_session_id"

    # åˆ›å»ºéš”ç¦»çš„æµ‹è¯•ç›®å½•
    setup_test_workspace "$env_type" "$test_session_id"

    # åˆå§‹åŒ–æµ‹è¯•ä»“åº“
    setup_test_repositories "$env_type"

    # é…ç½®æµ‹è¯•å·¥å…·
    setup_test_tools "$env_type"

    # éªŒè¯ç¯å¢ƒå°±ç»ªçŠ¶æ€
    validate_test_environment "$env_type"
}

# æµ‹è¯•å·¥ä½œç©ºé—´è®¾ç½®
setup_test_workspace() {
    local env_type="$1"
    local test_session_id="$2"

    local base_temp_dir="${ENV_CONFIG[${env_type}.temp_dir]}"
    export TEST_WORKSPACE="${base_temp_dir}/${test_session_id}"

    # åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„
    mkdir -p "$TEST_WORKSPACE"/{repos,configs,logs,artifacts}

    # è®¾ç½®æƒé™
    chmod 755 "$TEST_WORKSPACE"

    # åˆ›å»ºæµ‹è¯•é…ç½®
    cat > "$TEST_WORKSPACE/configs/test.conf" <<EOF
# æµ‹è¯•ç¯å¢ƒé…ç½®
TEST_SESSION_ID="$test_session_id"
TEST_ENV_TYPE="$env_type"
TEST_ISOLATION_LEVEL="${ENV_CONFIG[${env_type}.isolation]}"
TEST_CLEANUP_LEVEL="${ENV_CONFIG[${env_type}.cleanup]}"

# Codex Father é…ç½®
CODEX_SESSIONS_ROOT="$TEST_WORKSPACE/sessions"
CODEX_LOG_LEVEL="debug"
CODEX_DRY_RUN="true"
EOF

    export TEST_CONFIG_FILE="$TEST_WORKSPACE/configs/test.conf"
    log_info "æµ‹è¯•å·¥ä½œç©ºé—´åˆ›å»º: $TEST_WORKSPACE"
}

# æµ‹è¯•ä»“åº“è®¾ç½®
setup_test_repositories() {
    local env_type="$1"

    # åˆ›å»ºæµ‹è¯•ç”¨çš„ Git ä»“åº“
    local test_repo_dir="$TEST_WORKSPACE/repos/test-repo"
    mkdir -p "$test_repo_dir"

    (
        cd "$test_repo_dir"
        git init --initial-branch=main
        git config user.name "Codex Father Test"
        git config user.email "test@codex-father.local"

        # åˆ›å»ºåˆå§‹æäº¤
        echo "# Test Repository" > README.md
        echo "test-data" > test-file.txt
        git add .
        git commit -m "Initial commit"

        # åˆ›å»ºæµ‹è¯•åˆ†æ”¯
        git checkout -b develop
        echo "develop branch content" > develop.txt
        git add .
        git commit -m "Add develop branch"
        git checkout main
    )

    # åˆ›å»º bare ä»“åº“ (æ¨¡æ‹Ÿè¿œç¨‹)
    local bare_repo_dir="$TEST_WORKSPACE/repos/test-repo-bare"
    git clone --bare "$test_repo_dir" "$bare_repo_dir"

    # é…ç½®è¿œç¨‹ä»“åº“
    (
        cd "$test_repo_dir"
        git remote add origin "$bare_repo_dir"
    )

    export TEST_REPO_DIR="$test_repo_dir"
    export TEST_BARE_REPO_DIR="$bare_repo_dir"
    log_info "æµ‹è¯•ä»“åº“è®¾ç½®å®Œæˆ: $test_repo_dir"
}
```

### 2.3 æµ‹è¯•ç”¨ä¾‹è®¾è®¡æ¡†æ¶

#### 2.3.1 å•å…ƒæµ‹è¯•è®¾è®¡æ¨¡å¼

```bash
#!/usr/bin/env bats
# tests/unit/git_workflow_test.bats

# æµ‹è¯•è®¾ç½®å’Œæ¸…ç†
setup() {
    # åŠ è½½æµ‹è¯•åº“
    load '../lib/test-helper'
    load '../lib/git-test-helper'
    load '../lib/mock-helper'

    # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    setup_isolated_test_env
    setup_test_git_repo

    # åŠ è½½è¢«æµ‹è¯•æ¨¡å—
    source "$PROJECT_ROOT/lib/git_workflow.sh"
}

teardown() {
    cleanup_test_env
}

# æµ‹è¯•ç”¨ä¾‹: åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ - æ­£å¸¸æƒ…å†µ
@test "git_workflow: create_feature_branch - æ­£å¸¸åˆ›å»º" {
    # å‡†å¤‡
    local task_id="test-12345"
    local description="æµ‹è¯•åŠŸèƒ½åˆ†æ”¯"
    local base_branch="main"

    # æ‰§è¡Œ
    run create_feature_branch "$task_id" "$description" "$base_branch"

    # éªŒè¯
    assert_success
    assert_output --partial "æˆåŠŸåˆ›å»ºåŠŸèƒ½åˆ†æ”¯"

    # éªŒè¯åˆ†æ”¯å­˜åœ¨
    run git branch --list "feature/codex-task-$task_id"
    assert_success
    assert_output --partial "feature/codex-task-$task_id"

    # éªŒè¯åˆ†æ”¯çŠ¶æ€æ–‡ä»¶
    local state_file=".codex-father/git-state/${task_id}.json"
    assert_file_exists "$state_file"
    assert_json_contains "$state_file" '.status' 'created'
    assert_json_contains "$state_file" '.branchName' "feature/codex-task-$task_id"
}

# æµ‹è¯•ç”¨ä¾‹: åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ - åˆ†æ”¯å·²å­˜åœ¨
@test "git_workflow: create_feature_branch - åˆ†æ”¯å·²å­˜åœ¨" {
    # å‡†å¤‡
    local task_id="test-12345"
    local description="æµ‹è¯•åŠŸèƒ½åˆ†æ”¯"
    local branch_name="feature/codex-task-$task_id"

    # é¢„å…ˆåˆ›å»ºåˆ†æ”¯
    git checkout -b "$branch_name"
    git checkout main

    # æ‰§è¡Œ
    run create_feature_branch "$task_id" "$description"

    # éªŒè¯
    assert_failure 2  # åˆ†æ”¯å·²å­˜åœ¨çš„é”™è¯¯ç 
    assert_output --partial "åˆ†æ”¯.*å·²å­˜åœ¨"
}

# æµ‹è¯•ç”¨ä¾‹: ä»£ç æäº¤ - æœ‰å˜æ›´
@test "git_workflow: commit_task_changes - æœ‰ä»£ç å˜æ›´" {
    # å‡†å¤‡
    local task_id="test-12345"
    create_feature_branch "$task_id" "æµ‹è¯•åˆ†æ”¯"

    # åˆ›å»ºä»£ç å˜æ›´
    echo "æ–°åŠŸèƒ½ä»£ç " > new-feature.js
    echo "ä¿®æ”¹å†…å®¹" >> existing-file.txt

    # æ‰§è¡Œ
    run commit_task_changes "$task_id" "å®ç°æ–°åŠŸèƒ½"

    # éªŒè¯
    assert_success
    assert_output --partial "ä»£ç æäº¤æˆåŠŸ"

    # éªŒè¯æäº¤å­˜åœ¨
    run git log --oneline -1
    assert_success
    assert_output --partial "codex-task-$task_id"
    assert_output --partial "å®ç°æ–°åŠŸèƒ½"
}

# æµ‹è¯•ç”¨ä¾‹: PR åˆ›å»º - æ¨¡æ‹Ÿ GitHub CLI
@test "git_workflow: push_and_create_pr - æˆåŠŸåˆ›å»ºPR" {
    # å‡†å¤‡
    local task_id="test-12345"
    create_feature_branch "$task_id" "æµ‹è¯•åˆ†æ”¯"

    # åˆ›å»ºå˜æ›´å¹¶æäº¤
    echo "feature code" > feature.js
    commit_task_changes "$task_id" "æ·»åŠ åŠŸèƒ½"

    # æ¨¡æ‹Ÿ GitHub CLI
    mock_command "gh" "echo 'https://github.com/test/repo/pull/123'"

    # æ‰§è¡Œ
    run push_and_create_pr "$task_id" "åŠŸèƒ½PR" "æ·»åŠ æ–°åŠŸèƒ½çš„PR"

    # éªŒè¯
    assert_success
    assert_output --partial "PRåˆ›å»ºæˆåŠŸ"
    assert_output --partial "https://github.com/test/repo/pull/123"

    # éªŒè¯çŠ¶æ€æ›´æ–°
    local state_file=".codex-father/git-state/${task_id}.json"
    assert_json_contains "$state_file" '.status' 'pr_created'
    assert_json_contains "$state_file" '.prUrl' 'https://github.com/test/repo/pull/123'
}
```

#### 2.3.2 é›†æˆæµ‹è¯•è®¾è®¡æ¨¡å¼

```bash
#!/usr/bin/env bats
# tests/integration/mcp_git_integration_test.bats

setup() {
    load '../lib/test-helper'
    load '../lib/mcp-test-helper'
    load '../lib/integration-helper'

    # å¯åŠ¨ MCP æœåŠ¡å™¨
    start_test_mcp_server
    setup_test_git_environment
}

teardown() {
    stop_test_mcp_server
    cleanup_integration_test_env
}

# é›†æˆæµ‹è¯•: MCP Git å·¥å…·å®Œæ•´æµç¨‹
@test "integration: MCP Git å·¥å…·å®Œæ•´å·¥ä½œæµ" {
    # Step 1: é€šè¿‡ MCP åˆ›å»ºä»»åŠ¡
    local task_response
    task_response=$(call_mcp_tool "codex.task.create" '{
        "description": "é›†æˆæµ‹è¯•ä»»åŠ¡",
        "enableGitWorkflow": true,
        "baseBranch": "main",
        "autoCreatePR": true
    }')

    assert_json_success "$task_response"
    local task_id
    task_id=$(echo "$task_response" | jq -r '.result.taskId')

    # Step 2: éªŒè¯åˆ†æ”¯åˆ›å»º
    local branch_response
    branch_response=$(call_mcp_tool "codex.git.branch" '{
        "action": "status",
        "taskId": "'"$task_id"'"
    }')

    assert_json_success "$branch_response"
    assert_json_contains "$branch_response" '.result.status.status' 'created'

    # Step 3: æ¨¡æ‹Ÿä»£ç å˜æ›´å’Œæäº¤
    echo "integration test code" > "$TEST_REPO_DIR/integration-feature.js"
    cd "$TEST_REPO_DIR"

    local commit_response
    commit_response=$(call_mcp_tool "codex.git.commit" '{
        "taskId": "'"$task_id"'",
        "message": "æ·»åŠ é›†æˆæµ‹è¯•åŠŸèƒ½"
    }')

    assert_json_success "$commit_response"

    # Step 4: éªŒè¯æäº¤ç»“æœ
    run git log --oneline -1
    assert_success
    assert_output --partial "codex-task-$task_id"

    # Step 5: åˆ›å»º PR (æ¨¡æ‹Ÿ)
    mock_command "gh" "echo 'https://github.com/test/repo/pull/456'"

    local pr_response
    pr_response=$(call_mcp_tool "codex.git.pr" '{
        "taskId": "'"$task_id"'",
        "title": "é›†æˆæµ‹è¯•PR",
        "description": "è¿™æ˜¯ä¸€ä¸ªé›†æˆæµ‹è¯•åˆ›å»ºçš„PR"
    }')

    assert_json_success "$pr_response"
    assert_json_contains "$pr_response" '.result.prUrl' 'https://github.com/test/repo/pull/456'

    # Step 6: éªŒè¯æœ€ç»ˆçŠ¶æ€
    local final_status
    final_status=$(call_mcp_tool "codex.task.status" '{
        "taskId": "'"$task_id"'"
    }')

    assert_json_success "$final_status"
    assert_json_contains "$final_status" '.result.gitWorkflow.prUrl' 'https://github.com/test/repo/pull/456'
}
```

#### 2.3.3 ç«¯åˆ°ç«¯æµ‹è¯•è®¾è®¡æ¨¡å¼

```bash
#!/usr/bin/env bats
# tests/e2e/claude_code_integration_test.bats

setup() {
    load '../lib/test-helper'
    load '../lib/e2e-helper'
    load '../lib/claude-code-simulator'

    # è®¾ç½®å®Œæ•´çš„ E2E æµ‹è¯•ç¯å¢ƒ
    setup_e2e_test_environment
    start_full_test_stack
}

teardown() {
    stop_full_test_stack
    cleanup_e2e_test_environment
}

# E2E æµ‹è¯•: Claude Code å®Œæ•´ä»»åŠ¡å§”æ‰˜æµç¨‹
@test "e2e: Claude Code ä»»åŠ¡å§”æ‰˜å®Œæ•´æµç¨‹" {
    # æ¨¡æ‹Ÿ Claude Code çš„ä»»åŠ¡å§”æ‰˜è¯·æ±‚
    local claude_request='{
        "request": "ä½¿ç”¨codex-fatherå®Œæˆä¸€ä¸ªç®€å•çš„JavaScriptå‡½æ•°å¼€å‘ä»»åŠ¡",
        "taskDescription": "åˆ›å»ºä¸€ä¸ªè®¡ç®—ä¸¤ä¸ªæ•°å­—å’Œçš„å‡½æ•°",
        "requirements": ["åˆ›å»ºsum.jsæ–‡ä»¶", "åŒ…å«addå‡½æ•°", "æ·»åŠ åŸºæœ¬çš„é”™è¯¯å¤„ç†"],
        "enableGitWorkflow": true,
        "deadline": "1å°æ—¶"
    }'

    # Step 1: Claude Code é€šè¿‡ MCP åˆ›å»ºä»»åŠ¡
    log_info "Step 1: åˆ›å»ºå¼€å‘ä»»åŠ¡"
    local task_creation_result
    task_creation_result=$(simulate_claude_code_request "$claude_request")

    assert_json_success "$task_creation_result"
    local task_id
    task_id=$(echo "$task_creation_result" | jq -r '.taskId')
    log_info "ä»»åŠ¡åˆ›å»ºæˆåŠŸ: $task_id"

    # Step 2: éªŒè¯ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€
    log_info "Step 2: æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€"
    sleep 2  # ç­‰å¾…ä»»åŠ¡å¤„ç†

    local queue_status
    queue_status=$(simulate_claude_code_monitor "$task_id")
    assert_json_contains "$queue_status" '.status' 'in_progress'

    # Step 3: æ¨¡æ‹Ÿ Codex æ‰§è¡Œè¿‡ç¨‹ (å®é™…åœ¨åå°è¿è¡Œ)
    log_info "Step 3: æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹"

    # ç­‰å¾…ä»»åŠ¡æ‰§è¡Œ (æ¨¡æ‹Ÿ)
    local max_wait=300  # 5åˆ†é’Ÿè¶…æ—¶
    local wait_count=0
    while [[ $wait_count -lt $max_wait ]]; do
        local current_status
        current_status=$(simulate_claude_code_status_check "$task_id")
        local status
        status=$(echo "$current_status" | jq -r '.status')

        if [[ "$status" == "completed" || "$status" == "failed" ]]; then
            break
        fi

        sleep 5
        ((wait_count += 5))
    done

    # Step 4: éªŒè¯ä»»åŠ¡å®ŒæˆçŠ¶æ€
    log_info "Step 4: éªŒè¯ä»»åŠ¡å®ŒæˆçŠ¶æ€"
    local final_status
    final_status=$(simulate_claude_code_status_check "$task_id")

    assert_json_contains "$final_status" '.status' 'completed'
    assert_json_contains "$final_status" '.gitWorkflow.enabled' 'true'

    # Step 5: éªŒè¯ Git å·¥ä½œæµç»“æœ
    log_info "Step 5: éªŒè¯Gitå·¥ä½œæµ"
    local git_status
    git_status=$(echo "$final_status" | jq -r '.gitWorkflow')

    # éªŒè¯åˆ†æ”¯åˆ›å»º
    assert_json_contains "$git_status" '.branchName' "feature/codex-task-$task_id"

    # éªŒè¯ PR åˆ›å»º
    local pr_url
    pr_url=$(echo "$git_status" | jq -r '.prUrl')
    assert_not_null "$pr_url"
    assert_contains "$pr_url" "github.com"

    # Step 6: éªŒè¯ä»£ç äº¤ä»˜ç‰©
    log_info "Step 6: éªŒè¯ä»£ç äº¤ä»˜ç‰©"
    local session_dir=".codex-father/sessions/$task_id"

    # æ£€æŸ¥ä¼šè¯æ—¥å¿—
    assert_file_exists "$session_dir/job.log"
    assert_file_contains "$session_dir/job.log" "CONTROL: DONE"

    # æ£€æŸ¥ä»£ç æ–‡ä»¶ (å¦‚æœåœ¨å·¥ä½œç›®å½•ä¸­)
    if [[ -f "sum.js" ]]; then
        assert_file_contains "sum.js" "function add"
        assert_file_contains "sum.js" "error"
    fi

    # Step 7: Claude Code è·å–æœ€ç»ˆç»“æœ
    log_info "Step 7: è·å–ä»»åŠ¡ç»“æœ"
    local task_result
    task_result=$(simulate_claude_code_get_result "$task_id")

    assert_json_contains "$task_result" '.success' 'true'
    assert_json_contains "$task_result" '.deliverables.prUrl' "$pr_url"

    log_info "E2E æµ‹è¯•å®Œæˆ: ä»»åŠ¡ $task_id æˆåŠŸå®Œæˆ"
}
```

### 2.4 å®‰å…¨æµ‹è¯•è®¾è®¡

#### 2.4.1 å®‰å…¨æ‰«ææ¡†æ¶ (tests/security/security-scanner.sh)

```bash
#!/bin/bash
# tests/security/security-scanner.sh

# å®‰å…¨æ‰«æé…ç½®
readonly SECURITY_RESULTS_DIR="tests/results/security"
readonly SECURITY_CONFIG_DIR="tests/config/security"

# å®‰å…¨æ‰«æå·¥å…·é…ç½®
declare -A SECURITY_TOOLS=(
    ["shellcheck"]="bash script security analysis"
    ["eslint-security"]="typescript security linting"
    ["npm-audit"]="dependency vulnerability scan"
    ["git-secrets"]="sensitive data detection"
    ["custom-security"]="custom security rules"
)

# ä¸»è¦å®‰å…¨æ‰«æå‡½æ•°
run_security_scan() {
    local scan_type="$1"
    local target_path="$2"

    log_info "å¼€å§‹å®‰å…¨æ‰«æ: $scan_type"

    case "$scan_type" in
        "shellcheck")
            run_shellcheck_scan "$target_path"
            ;;
        "eslint-security")
            run_eslint_security_scan "$target_path"
            ;;
        "npm-audit")
            run_npm_audit_scan "$target_path"
            ;;
        "git-secrets")
            run_git_secrets_scan "$target_path"
            ;;
        "custom-security")
            run_custom_security_scan "$target_path"
            ;;
        "all")
            run_all_security_scans "$target_path"
            ;;
        *)
            log_error "æœªçŸ¥çš„å®‰å…¨æ‰«æç±»å‹: $scan_type"
            return 1
            ;;
    esac
}

# ShellCheck å®‰å…¨æ‰«æ
run_shellcheck_scan() {
    local target_path="$1"
    local report_file="${SECURITY_RESULTS_DIR}/shellcheck-report.json"

    log_info "è¿è¡Œ ShellCheck å®‰å…¨æ‰«æ"

    # æ”¶é›†æ‰€æœ‰ bash è„šæœ¬
    local script_files=()
    while IFS= read -r -d '' file; do
        script_files+=("$file")
    done < <(find "$target_path" -name "*.sh" -type f -print0)

    if [[ ${#script_files[@]} -eq 0 ]]; then
        log_warn "æ²¡æœ‰æ‰¾åˆ° bash è„šæœ¬æ–‡ä»¶"
        return 0
    fi

    log_info "æ‰«æ ${#script_files[@]} ä¸ª bash è„šæœ¬"

    # è¿è¡Œ ShellCheck
    local shellcheck_results=()
    local total_issues=0
    local critical_issues=0

    for script in "${script_files[@]}"; do
        local script_result
        script_result=$(shellcheck -f json "$script" 2>/dev/null || true)

        if [[ -n "$script_result" ]]; then
            shellcheck_results+=("$script_result")

            # ç»Ÿè®¡é—®é¢˜æ•°é‡
            local issues
            issues=$(echo "$script_result" | jq length)
            total_issues=$((total_issues + issues))

            # ç»Ÿè®¡ä¸¥é‡é—®é¢˜
            local critical
            critical=$(echo "$script_result" | jq '[.[] | select(.level == "error")] | length')
            critical_issues=$((critical_issues + critical))
        fi
    done

    # ç”Ÿæˆå®‰å…¨æŠ¥å‘Š
    generate_shellcheck_report "$report_file" shellcheck_results "$total_issues" "$critical_issues"

    # æ£€æŸ¥å®‰å…¨æ ‡å‡†
    if [[ $critical_issues -gt 0 ]]; then
        log_error "ShellCheck å‘ç° $critical_issues ä¸ªä¸¥é‡å®‰å…¨é—®é¢˜"
        return 1
    else
        log_info "ShellCheck å®‰å…¨æ‰«æé€šè¿‡ (æ€»é—®é¢˜: $total_issues)"
        return 0
    fi
}

# ESLint å®‰å…¨æ‰«æ
run_eslint_security_scan() {
    local target_path="$1"
    local report_file="${SECURITY_RESULTS_DIR}/eslint-security-report.json"

    log_info "è¿è¡Œ ESLint å®‰å…¨æ‰«æ"

    # æ£€æŸ¥æ˜¯å¦æœ‰ TypeScript/JavaScript æ–‡ä»¶
    local ts_files
    ts_files=$(find "$target_path" -name "*.ts" -o -name "*.js" | wc -l)

    if [[ $ts_files -eq 0 ]]; then
        log_info "æ²¡æœ‰ TypeScript/JavaScript æ–‡ä»¶éœ€è¦æ‰«æ"
        return 0
    fi

    # é…ç½® ESLint å®‰å…¨è§„åˆ™
    local eslint_config="${SECURITY_CONFIG_DIR}/eslint-security.json"
    create_eslint_security_config "$eslint_config"

    # è¿è¡Œ ESLint
    local eslint_result
    if eslint_result=$(npx eslint --config "$eslint_config" --format json "$target_path" 2>/dev/null); then
        echo "$eslint_result" > "$report_file"

        # åˆ†æç»“æœ
        local error_count
        error_count=$(echo "$eslint_result" | jq '[.[].messages[] | select(.severity == 2)] | length')

        if [[ $error_count -gt 0 ]]; then
            log_error "ESLint å‘ç° $error_count ä¸ªå®‰å…¨é”™è¯¯"
            return 1
        else
            log_info "ESLint å®‰å…¨æ‰«æé€šè¿‡"
            return 0
        fi
    else
        log_error "ESLint å®‰å…¨æ‰«æå¤±è´¥"
        return 1
    fi
}

# æ•æ„Ÿä¿¡æ¯æ£€æµ‹
run_git_secrets_scan() {
    local target_path="$1"
    local report_file="${SECURITY_RESULTS_DIR}/git-secrets-report.txt"

    log_info "è¿è¡Œæ•æ„Ÿä¿¡æ¯æ£€æµ‹"

    # æ•æ„Ÿä¿¡æ¯æ¨¡å¼
    local sensitive_patterns=(
        "ghp_[a-zA-Z0-9]{36}"                    # GitHub Personal Access Token
        "ghs_[a-zA-Z0-9]{36}"                    # GitHub App Token
        "github_pat_[a-zA-Z0-9_]{82}"            # GitHub Fine-grained Token
        "sk-[a-zA-Z0-9]{48}"                     # OpenAI API Key
        "xoxb-[0-9]{12}-[0-9]{12}-[a-zA-Z0-9]{24}" # Slack Bot Token
        "AKIA[0-9A-Z]{16}"                       # AWS Access Key
        "-----BEGIN [A-Z ]+-----"                # Private Keys
    )

    local findings=()
    local total_findings=0

    # æ‰«ææ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
    while IFS= read -r -d '' file; do
        # è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶å’Œç‰¹å®šç›®å½•
        if file --mime "$file" | grep -q "charset=binary" || \
           [[ "$file" =~ \.(git|node_modules|\.codex-father)/ ]]; then
            continue
        fi

        # æ£€æŸ¥æ¯ä¸ªæ•æ„Ÿæ¨¡å¼
        for pattern in "${sensitive_patterns[@]}"; do
            if grep -n -E "$pattern" "$file" >/dev/null 2>&1; then
                local matches
                matches=$(grep -n -E "$pattern" "$file")
                findings+=("æ–‡ä»¶: $file")
                findings+=("æ¨¡å¼: $pattern")
                findings+=("åŒ¹é…: $matches")
                findings+=("---")
                ((total_findings++))
            fi
        done
    done < <(find "$target_path" -type f -print0)

    # ç”ŸæˆæŠ¥å‘Š
    if [[ ${#findings[@]} -gt 0 ]]; then
        printf '%s\n' "${findings[@]}" > "$report_file"
        log_error "å‘ç° $total_findings ä¸ªæ•æ„Ÿä¿¡æ¯æ³„éœ²"
        return 1
    else
        echo "æœªå‘ç°æ•æ„Ÿä¿¡æ¯æ³„éœ²" > "$report_file"
        log_info "æ•æ„Ÿä¿¡æ¯æ£€æµ‹é€šè¿‡"
        return 0
    fi
}

# è‡ªå®šä¹‰å®‰å…¨è§„åˆ™æ£€æŸ¥
run_custom_security_scan() {
    local target_path="$1"
    local report_file="${SECURITY_RESULTS_DIR}/custom-security-report.json"

    log_info "è¿è¡Œè‡ªå®šä¹‰å®‰å…¨è§„åˆ™æ£€æŸ¥"

    local security_issues=()

    # æ£€æŸ¥1: æœªè½¬ä¹‰çš„ç”¨æˆ·è¾“å…¥
    log_info "æ£€æŸ¥æœªè½¬ä¹‰çš„ç”¨æˆ·è¾“å…¥"
    while IFS= read -r -d '' file; do
        if [[ "$file" =~ \.sh$ ]]; then
            # æ£€æŸ¥ç›´æ¥ä½¿ç”¨ $1, $2 ç­‰çš„æƒ…å†µ
            if grep -n 'echo.*\$[0-9]' "$file" >/dev/null; then
                security_issues+=({
                    "file": "$file",
                    "rule": "unescaped_user_input",
                    "severity": "medium",
                    "description": "ç›´æ¥è¾“å‡ºç”¨æˆ·è¾“å…¥å¯èƒ½å¯¼è‡´æ³¨å…¥æ”»å‡»"
                })
            fi
        fi
    done < <(find "$target_path" -name "*.sh" -print0)

    # æ£€æŸ¥2: ä¸å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶
    log_info "æ£€æŸ¥ä¸å®‰å…¨çš„ä¸´æ—¶æ–‡ä»¶ä½¿ç”¨"
    while IFS= read -r -d '' file; do
        if grep -n '/tmp/[^/]*\$' "$file" >/dev/null; then
            security_issues+=({
                "file": "$file",
                "rule": "insecure_temp_file",
                "severity": "high",
                "description": "ä½¿ç”¨å¯é¢„æµ‹çš„ä¸´æ—¶æ–‡ä»¶åå¯èƒ½å¯¼è‡´ç«äº‰æ¡ä»¶æ”»å‡»"
            })
        fi
    done < <(find "$target_path" -name "*.sh" -print0)

    # æ£€æŸ¥3: ç¡¬ç¼–ç çš„æ•æ„Ÿé…ç½®
    log_info "æ£€æŸ¥ç¡¬ç¼–ç çš„é…ç½®"
    local config_patterns=(
        "password.*="
        "secret.*="
        "token.*="
        "api_key.*="
    )

    for pattern in "${config_patterns[@]}"; do
        while IFS= read -r -d '' file; do
            if grep -i -n "$pattern" "$file" >/dev/null; then
                security_issues+=({
                    "file": "$file",
                    "rule": "hardcoded_secrets",
                    "severity": "high",
                    "description": "ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯"
                })
            fi
        done < <(find "$target_path" -type f -print0)
    done

    # ç”ŸæˆæŠ¥å‘Š
    local issues_count=${#security_issues[@]}
    local high_severity_count=0

    for issue in "${security_issues[@]}"; do
        if echo "$issue" | jq -r '.severity' | grep -q "high"; then
            ((high_severity_count++))
        fi
    done

    # åˆ›å»º JSON æŠ¥å‘Š
    {
        echo "{"
        echo "  \"timestamp\": \"$(date -Iseconds)\","
        echo "  \"totalIssues\": $issues_count,"
        echo "  \"highSeverityIssues\": $high_severity_count,"
        echo "  \"issues\": ["

        local first=true
        for issue in "${security_issues[@]}"; do
            if [[ "$first" == "true" ]]; then
                first=false
            else
                echo ","
            fi
            echo "    $issue"
        done

        echo "  ]"
        echo "}"
    } > "$report_file"

    if [[ $high_severity_count -gt 0 ]]; then
        log_error "å‘ç° $high_severity_count ä¸ªé«˜å±å®‰å…¨é—®é¢˜"
        return 1
    else
        log_info "è‡ªå®šä¹‰å®‰å…¨æ£€æŸ¥é€šè¿‡ (æ€»é—®é¢˜: $issues_count)"
        return 0
    fi
}
```

### 2.6 CI/CD é›†æˆè®¾è®¡

#### 2.6.1 GitHub Actions å·¥ä½œæµè®¾è®¡

```yaml
# .github/workflows/phase2-tests.yml
name: Phase 2 Tests

on:
  push:
    branches: [main, develop, feature/*]
  pull_request:
    branches: [main, develop]
  schedule:
    # æ¯æ—¥æ€§èƒ½åŸºå‡†æµ‹è¯•
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  BATS_VERSION: '1.8.2'

jobs:
  # å¿«é€Ÿæ£€æŸ¥ (å•å…ƒæµ‹è¯• + åŸºæœ¬å®‰å…¨æ‰«æ)
  quick-check:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'mcp/codex-mcp-server/package-lock.json'

      - name: Install BATS
        run: |
          wget -O bats.tar.gz https://github.com/bats-core/bats-core/archive/v${BATS_VERSION}.tar.gz
          tar -xzf bats.tar.gz
          sudo ./bats-core-${BATS_VERSION}/install.sh /usr/local

      - name: Install dependencies
        run: |
          cd mcp/codex-mcp-server
          npm ci

      - name: Run unit tests
        run: |
          ./tests/run-tests.sh unit
        env:
          TEST_ENV: ci
          BATS_LIB_PATH: /usr/local/lib

      - name: Run security scan (quick)
        run: |
          ./tests/run-tests.sh security --quick
        env:
          TEST_ENV: ci

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quick-check-results
          path: tests/results/
          retention-days: 7

  # å®Œæ•´é›†æˆæµ‹è¯•
  integration-tests:
    runs-on: ubuntu-latest
    needs: quick-check
    timeout-minutes: 30
    strategy:
      matrix:
        test-suite: [integration, e2e]
        node-version: [18, 20]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: 'mcp/codex-mcp-server/package-lock.json'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc git

      - name: Install BATS
        run: |
          wget -O bats.tar.gz https://github.com/bats-core/bats-core/archive/v${BATS_VERSION}.tar.gz
          tar -xzf bats.tar.gz
          sudo ./bats-core-${BATS_VERSION}/install.sh /usr/local

      - name: Install GitHub CLI
        run: |
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo gpg --dearmor -o /usr/share/keyrings/githubcli-archive-keyring.gpg
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          sudo apt update
          sudo apt install gh

      - name: Setup Git
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

      - name: Install project dependencies
        run: |
          cd mcp/codex-mcp-server
          npm ci
          npm run build

      - name: Run ${{ matrix.test-suite }} tests
        run: |
          ./tests/run-tests.sh ${{ matrix.test-suite }}
        env:
          TEST_ENV: ci
          NODE_VERSION: ${{ matrix.node-version }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.test-suite }}-results-node${{ matrix.node-version }}
          path: tests/results/
          retention-days: 7

  # å…¨é¢å®‰å…¨æ‰«æ
  security-scan:
    runs-on: ubuntu-latest
    needs: quick-check
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'mcp/codex-mcp-server/package-lock.json'

      - name: Install security tools
        run: |
          # ShellCheck
          sudo apt-get update
          sudo apt-get install -y shellcheck

          # ESLint security plugin
          cd mcp/codex-mcp-server
          npm ci
          npm install --save-dev eslint-plugin-security

      - name: Run comprehensive security scan
        run: |
          ./tests/run-tests.sh security --comprehensive
        env:
          TEST_ENV: ci

      - name: Upload security results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-results
          path: tests/results/security/
          retention-days: 30

      - name: Security Gate Check
        run: |
          if [[ -f tests/results/security/high-severity-issues ]]; then
            echo "::error::High severity security issues found!"
            cat tests/results/security/high-severity-issues
            exit 1
          fi

  # å¤šç¯å¢ƒå…¼å®¹æ€§æµ‹è¯•
  compatibility-tests:
    runs-on: ${{ matrix.os }}
    needs: quick-check
    strategy:
      matrix:
        os: [ubuntu-20.04, ubuntu-22.04, macos-12, macos-13]
        git-version: ['2.30', '2.35', 'latest']
        exclude:
          # macOS ä¸æµ‹è¯•æ—§ç‰ˆæœ¬ Git
          - os: macos-12
            git-version: '2.30'
          - os: macos-13
            git-version: '2.30'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup specific Git version
        if: matrix.git-version != 'latest'
        run: |
          # å®‰è£…ç‰¹å®šç‰ˆæœ¬çš„ Git (ç®€åŒ–å®ç°)
          echo "Installing Git ${{ matrix.git-version }}"
          # å®é™…å®ç°ä¼šæ ¹æ®æ“ä½œç³»ç»Ÿä¸‹è½½ç¼–è¯‘ç‰¹å®šç‰ˆæœ¬

      - name: Run compatibility tests
        run: |
          ./tests/run-tests.sh compatibility
        env:
          TEST_ENV: ci
          TEST_OS: ${{ matrix.os }}
          TEST_GIT_VERSION: ${{ matrix.git-version }}

      - name: Upload compatibility results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: compat-${{ matrix.os }}-git${{ matrix.git-version }}
          path: tests/results/compatibility/
          retention-days: 7

  # æµ‹è¯•æŠ¥å‘Šæ±‡æ€»
  test-summary:
    runs-on: ubuntu-latest
    needs: [quick-check, integration-tests, security-scan, compatibility-tests]
    if: always()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts/

      - name: Generate test summary
        run: |
          ./tests/scripts/generate-test-summary.sh test-artifacts/
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.html
          retention-days: 30

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
```

### 2.7 æµ‹è¯•æŠ¥å‘Šå’Œç›‘æ§è®¾è®¡

#### 2.7.1 æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨

```bash
#!/bin/bash
# tests/lib/report-generator.sh

# æŠ¥å‘Šç”Ÿæˆé…ç½®
readonly REPORT_TEMPLATE_DIR="tests/templates"
readonly REPORT_OUTPUT_DIR="tests/reports"

# ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š
generate_comprehensive_report() {
    local test_session_id="$1"
    local output_format="$2"  # html|json|markdown

    log_info "ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š: $test_session_id"

    local session_dir="${TEST_RESULTS_DIR}/${test_session_id}"
    local report_data_file="${session_dir}/report-data.json"

    # æ”¶é›†æ‰€æœ‰æµ‹è¯•æ•°æ®
    collect_test_data "$session_dir" "$report_data_file"

    # æ ¹æ®æ ¼å¼ç”ŸæˆæŠ¥å‘Š
    case "$output_format" in
        "html")
            generate_html_report "$report_data_file" "${REPORT_OUTPUT_DIR}/${test_session_id}.html"
            ;;
        "json")
            cp "$report_data_file" "${REPORT_OUTPUT_DIR}/${test_session_id}.json"
            ;;
        "markdown")
            generate_markdown_report "$report_data_file" "${REPORT_OUTPUT_DIR}/${test_session_id}.md"
            ;;
        *)
            log_error "ä¸æ”¯æŒçš„æŠ¥å‘Šæ ¼å¼: $output_format"
            return 1
            ;;
    esac
}

# æ”¶é›†æµ‹è¯•æ•°æ®
collect_test_data() {
    local session_dir="$1"
    local output_file="$2"

    local test_summary="{}"

    # æ”¶é›†åŸºæœ¬ä¿¡æ¯
    test_summary=$(echo "$test_summary" | jq --arg id "$(basename "$session_dir")" \
                                           --arg timestamp "$(date -Iseconds)" \
                                           '. + {
                                               "sessionId": $id,
                                               "timestamp": $timestamp,
                                               "environment": env.TEST_ENV // "unknown"
                                           }')

    # æ”¶é›†å•å…ƒæµ‹è¯•ç»“æœ
    if [[ -f "$session_dir/unit-tests.json" ]]; then
        local unit_results
        unit_results=$(cat "$session_dir/unit-tests.json")
        test_summary=$(echo "$test_summary" | jq --argjson unit "$unit_results" \
                                                '. + {"unitTests": $unit}')
    fi

    # æ”¶é›†é›†æˆæµ‹è¯•ç»“æœ
    if [[ -f "$session_dir/integration-tests.json" ]]; then
        local integration_results
        integration_results=$(cat "$session_dir/integration-tests.json")
        test_summary=$(echo "$test_summary" | jq --argjson integration "$integration_results" \
                                                '. + {"integrationTests": $integration}')
    fi

    # æ”¶é›†å®‰å…¨æ‰«æç»“æœ
    if [[ -d "$session_dir/security" ]]; then
        local security_results="{}"
        for security_file in "$session_dir/security"/*.json; do
            if [[ -f "$security_file" ]]; then
                local scan_type
                scan_type=$(basename "$security_file" .json)
                local security_data
                security_data=$(cat "$security_file")
                security_results=$(echo "$security_results" | jq --arg type "$scan_type" \
                                                                 --argjson data "$security_data" \
                                                                 '.[$type] = $data')
            fi
        done
        test_summary=$(echo "$test_summary" | jq --argjson security "$security_results" \
                                                '. + {"securityScans": $security}')
    fi

    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    test_summary=$(echo "$test_summary" | jq '. + {
        "summary": {
            "totalTests": ((.unitTests.summary.total // 0) + (.integrationTests.summary.total // 0)),
            "passedTests": ((.unitTests.summary.passed // 0) + (.integrationTests.summary.passed // 0)),
            "failedTests": ((.unitTests.summary.failed // 0) + (.integrationTests.summary.failed // 0)),
            "coverage": (.unitTests.coverage.overall // 0),
            "securityIssues": (.securityScans | [.[].totalIssues // 0] | add),
        }
    }')

    echo "$test_summary" > "$output_file"
}

# ç”Ÿæˆ HTML æŠ¥å‘Š
generate_html_report() {
    local data_file="$1"
    local output_file="$2"

    local template_file="${REPORT_TEMPLATE_DIR}/test-report.html.template"

    if [[ ! -f "$template_file" ]]; then
        create_html_template "$template_file"
    fi

    # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ HTML æŠ¥å‘Š
    local report_data
    report_data=$(cat "$data_file")

    # æ›¿æ¢æ¨¡æ¿å˜é‡
    sed -e "s|{{REPORT_DATA}}|$(echo "$report_data" | jq -c .)|g" \
        -e "s|{{GENERATION_TIME}}|$(date)|g" \
        "$template_file" > "$output_file"

    log_info "HTML æŠ¥å‘Šç”Ÿæˆ: $output_file"
}

# ç”Ÿæˆ Markdown æŠ¥å‘Š
generate_markdown_report() {
    local data_file="$1"
    local output_file="$2"

    local report_data
    report_data=$(cat "$data_file")

    # è§£ææ•°æ®
    local session_id
    session_id=$(echo "$report_data" | jq -r '.sessionId')
    local timestamp
    timestamp=$(echo "$report_data" | jq -r '.timestamp')
    local total_tests
    total_tests=$(echo "$report_data" | jq -r '.summary.totalTests')
    local passed_tests
    passed_tests=$(echo "$report_data" | jq -r '.summary.passedTests')
    local failed_tests
    failed_tests=$(echo "$report_data" | jq -r '.summary.failedTests')
    local coverage
    coverage=$(echo "$report_data" | jq -r '.summary.coverage')

    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    cat > "$output_file" <<EOF
# æµ‹è¯•æŠ¥å‘Š - $session_id

**ç”Ÿæˆæ—¶é—´**: $timestamp

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»æµ‹è¯•æ•° | $total_tests |
| é€šè¿‡æµ‹è¯• | $passed_tests |
| å¤±è´¥æµ‹è¯• | $failed_tests |
| æˆåŠŸç‡ | $(echo "scale=2; $passed_tests * 100 / $total_tests" | bc)% |
| ä»£ç è¦†ç›–ç‡ | ${coverage}% |

## âœ… å•å…ƒæµ‹è¯•ç»“æœ

EOF

    # æ·»åŠ å•å…ƒæµ‹è¯•è¯¦æƒ…
    if echo "$report_data" | jq -e '.unitTests' >/dev/null; then
        echo "$report_data" | jq -r '.unitTests.tests[]? | "- \(.name): \(.status)"' >> "$output_file"
    fi

    cat >> "$output_file" <<EOF

## ğŸ”— é›†æˆæµ‹è¯•ç»“æœ

EOF

    # æ·»åŠ é›†æˆæµ‹è¯•è¯¦æƒ…
    if echo "$report_data" | jq -e '.integrationTests' >/dev/null; then
        echo "$report_data" | jq -r '.integrationTests.tests[]? | "- \(.name): \(.status)"' >> "$output_file"
    fi

    cat >> "$output_file" <<EOF

## âš¡ æ€§èƒ½æµ‹è¯•ç»“æœ

EOF

    # æ·»åŠ æ€§èƒ½æµ‹è¯•è¯¦æƒ…
    if echo "$report_data" | jq -e '.performanceTests' >/dev/null; then
        echo "$report_data" | jq -r '.performanceTests | to_entries[] | "- \(.key): \(.value.performance.time.average)s (æœŸæœ›: \(.value.performance.time.expected)s)"' >> "$output_file"
    fi

    cat >> "$output_file" <<EOF

## ğŸ›¡ï¸ å®‰å…¨æ‰«æç»“æœ

EOF

    # æ·»åŠ å®‰å…¨æ‰«æè¯¦æƒ…
    if echo "$report_data" | jq -e '.securityScans' >/dev/null; then
        echo "$report_data" | jq -r '.securityScans | to_entries[] | "- \(.key): \(.value.totalIssues // 0) ä¸ªé—®é¢˜"' >> "$output_file"
    fi

    cat >> "$output_file" <<EOF

---
*æŠ¥å‘Šç”± Codex Father æµ‹è¯•æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ*
EOF

    log_info "Markdown æŠ¥å‘Šç”Ÿæˆ: $output_file"
}
```

### 2.8 æŒç»­ç›‘æ§å’Œè´¨é‡é—¨æ§

#### 2.8.1 è´¨é‡é—¨æ§å®ç°

```bash
#!/bin/bash
# tests/lib/quality-gates.sh

# è´¨é‡é—¨æ§é…ç½®
readonly QG_CONFIG_FILE="tests/config/quality-gates.json"
readonly QG_RESULTS_DIR="tests/results/quality-gates"

# é»˜è®¤è´¨é‡æ ‡å‡†
declare -A QUALITY_STANDARDS=(
    ["test_pass_rate"]="95"
    ["code_coverage"]="80"
    ["performance_regression"]="20"
    ["security_high_issues"]="0"
    ["security_medium_issues"]="5"
)

# è´¨é‡é—¨æ§æ£€æŸ¥
run_quality_gates() {
    local test_session_id="$1"

    log_info "è¿è¡Œè´¨é‡é—¨æ§æ£€æŸ¥: $test_session_id"

    local session_dir="${TEST_RESULTS_DIR}/${test_session_id}"
    local gate_results_file="${QG_RESULTS_DIR}/${test_session_id}-gates.json"

    mkdir -p "$QG_RESULTS_DIR"

    # åˆå§‹åŒ–é—¨æ§ç»“æœ
    local gate_results='{"timestamp": "'$(date -Iseconds)'", "gates": {}}'

    # æ£€æŸ¥æµ‹è¯•é€šè¿‡ç‡
    local test_pass_gate
    test_pass_gate=$(check_test_pass_rate "$session_dir")
    gate_results=$(echo "$gate_results" | jq --argjson gate "$test_pass_gate" \
                                           '.gates.testPassRate = $gate')

    # æ£€æŸ¥ä»£ç è¦†ç›–ç‡
    local coverage_gate
    coverage_gate=$(check_code_coverage "$session_dir")
    gate_results=$(echo "$gate_results" | jq --argjson gate "$coverage_gate" \
                                           '.gates.codeCoverage = $gate')

    # æ£€æŸ¥æ€§èƒ½å›å½’
    local performance_gate
    performance_gate=$(check_performance_regression "$session_dir")
    gate_results=$(echo "$gate_results" | jq --argjson gate "$performance_gate" \
                                           '.gates.performanceRegression = $gate')

    # æ£€æŸ¥å®‰å…¨é—®é¢˜
    local security_gate
    security_gate=$(check_security_issues "$session_dir")
    gate_results=$(echo "$gate_results" | jq --argjson gate "$security_gate" \
                                           '.gates.securityIssues = $gate')

    # è®¡ç®—æ€»ä½“é€šè¿‡çŠ¶æ€
    local overall_passed
    overall_passed=$(echo "$gate_results" | jq '[.gates[].passed] | all')
    gate_results=$(echo "$gate_results" | jq --argjson passed "$overall_passed" \
                                           '. + {"overallPassed": $passed}')

    # ä¿å­˜ç»“æœ
    echo "$gate_results" > "$gate_results_file"

    # è¾“å‡ºç»“æœ
    log_info "è´¨é‡é—¨æ§æ£€æŸ¥å®Œæˆ"
    echo "$gate_results" | jq -r '.gates | to_entries[] | "\(.key): \(if .value.passed then "âœ… PASSED" else "âŒ FAILED" end) (\(.value.actual) / \(.value.threshold))"'

    if [[ "$overall_passed" == "true" ]]; then
        log_info "âœ… æ‰€æœ‰è´¨é‡é—¨æ§æ£€æŸ¥é€šè¿‡"
        return 0
    else
        log_error "âŒ è´¨é‡é—¨æ§æ£€æŸ¥å¤±è´¥"
        return 1
    fi
}

# æ£€æŸ¥æµ‹è¯•é€šè¿‡ç‡
check_test_pass_rate() {
    local session_dir="$1"
    local threshold="${QUALITY_STANDARDS[test_pass_rate]}"

    local total_tests=0
    local passed_tests=0

    # ç»Ÿè®¡å•å…ƒæµ‹è¯•
    if [[ -f "$session_dir/unit-tests.json" ]]; then
        local unit_total unit_passed
        unit_total=$(jq -r '.summary.total // 0' "$session_dir/unit-tests.json")
        unit_passed=$(jq -r '.summary.passed // 0' "$session_dir/unit-tests.json")
        total_tests=$((total_tests + unit_total))
        passed_tests=$((passed_tests + unit_passed))
    fi

    # ç»Ÿè®¡é›†æˆæµ‹è¯•
    if [[ -f "$session_dir/integration-tests.json" ]]; then
        local integration_total integration_passed
        integration_total=$(jq -r '.summary.total // 0' "$session_dir/integration-tests.json")
        integration_passed=$(jq -r '.summary.passed // 0' "$session_dir/integration-tests.json")
        total_tests=$((total_tests + integration_total))
        passed_tests=$((passed_tests + integration_passed))
    fi

    local pass_rate=0
    if [[ $total_tests -gt 0 ]]; then
        pass_rate=$(echo "scale=2; $passed_tests * 100 / $total_tests" | bc)
    fi

    local passed
    passed=$(echo "$pass_rate >= $threshold" | bc)

    cat <<EOF
{
    "name": "testPassRate",
    "description": "æµ‹è¯•é€šè¿‡ç‡æ£€æŸ¥",
    "threshold": $threshold,
    "actual": $pass_rate,
    "passed": $(if [[ $passed -eq 1 ]]; then echo "true"; else echo "false"; fi),
    "details": {
        "totalTests": $total_tests,
        "passedTests": $passed_tests,
        "failedTests": $((total_tests - passed_tests))
    }
}
EOF
}

# æ£€æŸ¥ä»£ç è¦†ç›–ç‡
check_code_coverage() {
    local session_dir="$1"
    local threshold="${QUALITY_STANDARDS[code_coverage]}"

    local coverage=0

    # è·å–è¦†ç›–ç‡æ•°æ®
    if [[ -f "$session_dir/coverage.json" ]]; then
        coverage=$(jq -r '.overall // 0' "$session_dir/coverage.json")
    elif [[ -f "$session_dir/unit-tests.json" ]]; then
        coverage=$(jq -r '.coverage.overall // 0' "$session_dir/unit-tests.json")
    fi

    local passed
    passed=$(echo "$coverage >= $threshold" | bc)

    cat <<EOF
{
    "name": "codeCoverage",
    "description": "ä»£ç è¦†ç›–ç‡æ£€æŸ¥",
    "threshold": $threshold,
    "actual": $coverage,
    "passed": $(if [[ $passed -eq 1 ]]; then echo "true"; else echo "false"; fi),
    "details": {
        "coveragePercentage": $coverage
    }
}
EOF
}

# æ£€æŸ¥æ€§èƒ½å›å½’
        "maxRegressionPercentage": $max_regression,
        "hasRegression": $has_regression
    }
}
EOF
}

# æ£€æŸ¥å®‰å…¨é—®é¢˜
check_security_issues() {
    local session_dir="$1"
    local high_threshold="${QUALITY_STANDARDS[security_high_issues]}"
    local medium_threshold="${QUALITY_STANDARDS[security_medium_issues]}"

    local high_issues=0
    local medium_issues=0
    local total_issues=0

    # ç»Ÿè®¡å®‰å…¨é—®é¢˜
    if [[ -d "$session_dir/security" ]]; then
        for security_file in "$session_dir/security"/*.json; do
            if [[ -f "$security_file" ]]; then
                local file_high file_medium
                file_high=$(jq -r '.highSeverityIssues // 0' "$security_file")
                file_medium=$(jq -r '.mediumSeverityIssues // 0' "$security_file")
                high_issues=$((high_issues + file_high))
                medium_issues=$((medium_issues + file_medium))
                total_issues=$((total_issues + $(jq -r '.totalIssues // 0' "$security_file")))
            fi
        done
    fi

    local passed=true
    if [[ $high_issues -gt $high_threshold ]] || [[ $medium_issues -gt $medium_threshold ]]; then
        passed=false
    fi

    cat <<EOF
{
    "name": "securityIssues",
    "description": "å®‰å…¨é—®é¢˜æ£€æŸ¥",
    "threshold": {
        "high": $high_threshold,
        "medium": $medium_threshold
    },
    "actual": {
        "high": $high_issues,
        "medium": $medium_issues,
        "total": $total_issues
    },
    "passed": $passed,
    "details": {
        "highSeverityIssues": $high_issues,
        "mediumSeverityIssues": $medium_issues,
        "totalIssues": $total_issues
    }
}
EOF
}
```

## 3. éƒ¨ç½²å’Œå®æ–½è®¡åˆ’

### 3.1 å®æ–½æ—¶é—´çº¿

```mermaid
gantt
    title Phase 2 æµ‹è¯•ä½“ç³»å®æ–½è®¡åˆ’
    dateFormat  YYYY-MM-DD
    section åŸºç¡€è®¾æ–½
    æµ‹è¯•æ¡†æ¶æ­å»º      :framework, 2025-09-27, 1d
    CI/CDé›†æˆ        :cicd, after framework, 1d
    section æµ‹è¯•å¼€å‘
    å•å…ƒæµ‹è¯•å¼€å‘      :unit, after cicd, 1d
    é›†æˆæµ‹è¯•å¼€å‘      :integration, after unit, 1d
    section è´¨é‡ä¿è¯
    å®‰å…¨æµ‹è¯•é›†æˆ      :security, after integration, 1d
    è´¨é‡é—¨æ§å®æ–½      :quality, after security, 1d
    section éªŒæ”¶äº¤ä»˜
    æ•´ä½“æµ‹è¯•éªŒæ”¶      :acceptance, after quality, 1d
```

### 3.2 äº¤ä»˜æ¸…å•

**æ ¸å¿ƒäº¤ä»˜ç‰©**:

- [ ] å®Œæ•´çš„æµ‹è¯•æ¡†æ¶ (BATS + Jest + è‡ªå®šä¹‰)
- [ ] å…¨é¢çš„æµ‹è¯•ç”¨ä¾‹é›† (å•å…ƒã€é›†æˆã€E2Eã€æ€§èƒ½ã€å®‰å…¨)
- [ ] CI/CD é›†æˆé…ç½® (GitHub Actions)
- [ ] æµ‹è¯•æŠ¥å‘Šå’Œç›‘æ§ç³»ç»Ÿ
- [ ] è´¨é‡é—¨æ§æœºåˆ¶
- [ ] æµ‹è¯•æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—

**æ”¯æŒå·¥å…·**:

- [ ] æµ‹è¯•ç¯å¢ƒè‡ªåŠ¨åŒ–è„šæœ¬
- [ ] å®‰å…¨æ‰«æå·¥å…·é›†æˆ
- [ ] æµ‹è¯•æ•°æ®ç®¡ç†å·¥å…·

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0 **åˆ›å»ºæ—¥æœŸ**: 2025-09-26 **è´Ÿè´£äºº**: Claude Code é›†æˆé¡¹ç›®ç»„
**å®¡æ‰¹çŠ¶æ€**: å¾…å®¡æ‰¹
